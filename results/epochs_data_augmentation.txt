Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_21 (Conv2D)           (None, 28, 28, 32)        320
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 14, 14, 32)        0
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 14, 14, 64)        18496
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 7, 7, 64)          0
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 7, 7, 128)         73856
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 3, 3, 128)         0
_________________________________________________________________
flatten_6 (Flatten)          (None, 1152)              0
_________________________________________________________________
dense_10 (Dense)             (None, 512)               590336
_________________________________________________________________
dense_11 (Dense)             (None, 24)                12312
=================================================================
Total params: 695,320
Trainable params: 695,320
Non-trainable params: 0
_________________________________________________________________
Epoch 1/15
858/858 [==============================] - 22s 25ms/step - loss: 2.4532 - acc: 0.2318 - val_loss: 1.3888 - val_acc: 0.5045
Epoch 2/15
858/858 [==============================] - 21s 24ms/step - loss: 1.2995 - acc: 0.5621 - val_loss: 0.7157 - val_acc: 0.7422
Epoch 3/15
858/858 [==============================] - 20s 24ms/step - loss: 0.8147 - acc: 0.7226 - val_loss: 0.4772 - val_acc: 0.8459
Epoch 4/15
858/858 [==============================] - 21s 24ms/step - loss: 0.5726 - acc: 0.8065 - val_loss: 0.2770 - val_acc: 0.9080
Epoch 5/15
858/858 [==============================] - 24s 28ms/step - loss: 0.4286 - acc: 0.8551 - val_loss: 0.2015 - val_acc: 0.9208
Epoch 6/15
858/858 [==============================] - 25s 29ms/step - loss: 0.3430 - acc: 0.8848 - val_loss: 0.2430 - val_acc: 0.9208
Epoch 7/15
858/858 [==============================] - 30s 35ms/step - loss: 0.2982 - acc: 0.8993 - val_loss: 0.0874 - val_acc: 0.9760
Epoch 8/15
858/858 [==============================] - 19s 23ms/step - loss: 0.2535 - acc: 0.9160 - val_loss: 0.0718 - val_acc: 0.9782
Epoch 9/15
858/858 [==============================] - 20s 23ms/step - loss: 0.2269 - acc: 0.9228 - val_loss: 0.0550 - val_acc: 0.9831
Epoch 10/15
858/858 [==============================] - 24s 28ms/step - loss: 0.1995 - acc: 0.9343 - val_loss: 0.0731 - val_acc: 0.9742
Epoch 11/15
858/858 [==============================] - 24s 28ms/step - loss: 0.1833 - acc: 0.9383 - val_loss: 0.0705 - val_acc: 0.9731
Epoch 12/15
858/858 [==============================] - 26s 30ms/step - loss: 0.1670 - acc: 0.9427 - val_loss: 0.0432 - val_acc: 0.9877
Epoch 13/15
858/858 [==============================] - 22s 26ms/step - loss: 0.1493 - acc: 0.9501 - val_loss: 0.0414 - val_acc: 0.9852
Epoch 14/15
858/858 [==============================] - 23s 26ms/step - loss: 0.1496 - acc: 0.9492 - val_loss: 0.0677 - val_acc: 0.9815
Epoch 15/15
858/858 [==============================] - 26s 31ms/step - loss: 0.1334 - acc: 0.9564 - val_loss: 0.0306 - val_acc: 0.9919
The time taken to execute is 349.66 seconds.
